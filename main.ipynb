{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Import üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer,DataCollatorForTokenClassification,get_scheduler\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Parsing üìù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conllx(filepath):\n",
    "    \"\"\"\n",
    "    Reads a CoNLL-X formatted file and extracts tokens and tags for each sentence.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the CoNLL-X file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "            - sentences_tokens: List of token lists for each sentence.\n",
    "            - sentences_tags: List of tag lists for each sentence.\n",
    "    \"\"\"\n",
    "    sentences_tokens = []\n",
    "    sentences_tags = []\n",
    "    with open(filepath, 'r', encoding='utf8') as f:\n",
    "        tokens, tags = [], []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # End of a sentence\n",
    "                if tokens:\n",
    "                    sentences_tokens.append(tokens)\n",
    "                    sentences_tags.append(tags)\n",
    "                    tokens, tags = [], []  # Reset for the next sentence\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:  # Ensure the line has enough parts\n",
    "                    tokens.append(parts[1])  # Token is in the second column\n",
    "                    tags.append(parts[4])    # Tag is in the fifth column\n",
    "        # Append the last sentence if the file doesn't end with a blank line\n",
    "        if tokens:\n",
    "            sentences_tokens.append(tokens)\n",
    "            sentences_tags.append(tags)\n",
    "    return sentences_tokens, sentences_tags\n",
    "\n",
    "\n",
    "def load_data_from_folders(folders, base_path=\"wsj\"):\n",
    "    \"\"\"\n",
    "    Loads tokens and tags from multiple folders containing CoNLL-X files.\n",
    "\n",
    "    Args:\n",
    "        folders (list): List of folder names to process.\n",
    "        base_path (str): Base directory containing the folders.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "            - all_tokens: List of token lists for all sentences.\n",
    "            - all_tags: List of tag lists for all sentences.\n",
    "    \"\"\"\n",
    "    all_tokens = []\n",
    "    all_tags = []\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        # Iterate through all .conllx files in the folder\n",
    "        for file in glob.glob(os.path.join(folder_path, \"*.conllx\")):\n",
    "            tokens, tags = read_conllx(file)  # Read tokens and tags from the file\n",
    "            all_tokens.extend(tokens)  # Add tokens to the global list\n",
    "            all_tags.extend(tags)      # Add tags to the global list\n",
    "    return all_tokens, all_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split üóÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38219\n"
     ]
    }
   ],
   "source": [
    "train_folders = [f\"{i:02d}\" for i in range(0, 19)]     # Folders 00 to 18\n",
    "val_folders   = [f\"{i:02d}\" for i in range(19, 22)]    # Folders 19 to 21\n",
    "test_folders  = [f\"{i:02d}\" for i in range(22, 25)]    # Folders 22 to 24\n",
    "\n",
    "\n",
    "train_tokens, train_tags = load_data_from_folders(train_folders, base_path=\"wsj\")\n",
    "val_tokens, val_tags = load_data_from_folders(val_folders, base_path=\"wsj\")\n",
    "test_tokens, test_tags = load_data_from_folders(test_folders, base_path=\"wsj\")\n",
    "\n",
    "data_train = {\"tokens\": train_tokens, \"pos_tags\": train_tags}\n",
    "data_val   = {\"tokens\": val_tokens, \"pos_tags\": val_tags}\n",
    "data_test  = {\"tokens\": test_tokens, \"pos_tags\": test_tags}\n",
    "\n",
    "print(len(train_tokens))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tokenizer and Model ü§ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=True)\n",
    "\n",
    "label_list = sorted({tag for tags in data_train[\"pos_tags\"] for tag in tags})\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "#use bert for token classification\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(label_list), label2id=label_to_id, id2label={i: label for i, label in enumerate(label_list)})\n",
    "#set the device to cuda if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and Align Labels üìù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b936f8a0a7cc4271851366e278519f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de90f96c79b44e8b2db789576bea5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5527 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd59a33f51da4a848050de45a8ed119a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 38219\n",
      "Validation dataset size: 5527\n",
      "Test dataset size: 5462\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    all_labels = []\n",
    "    for i, labels in enumerate(examples[\"pos_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # Ignore special tokens\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # Assign the label for the first token of the word\n",
    "                label_ids.append(label_to_id.get(labels[word_idx], -100))\n",
    "            else:\n",
    "                # Assign -100 to subsequent tokens of the same word\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        all_labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Convert datasets to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_dict(data_train)\n",
    "val_dataset = Dataset.from_dict(data_val)\n",
    "test_dataset = Dataset.from_dict(data_test)\n",
    "\n",
    "# Apply the tokenization and alignment function\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ü¶æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rinal\\AppData\\Local\\Temp\\ipykernel_19024\\78034360.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6678' max='7167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6678/7167 12:35 < 00:55, 8.84 it/s, Epoch 2.79/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.076004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.070628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.070452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.067149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.067775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.068631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/3 [12:35<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Wrap the training process with tqdm for progress tracking\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(training_args.num_train_epochs), desc=\u001b[33m\"\u001b[39m\u001b[33mEpochs\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[32m     37\u001b[39m trainer.save_model(\u001b[33m\"\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rinal\\Desktop\\UNIBO\\NLP2\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rinal\\Desktop\\UNIBO\\NLP2\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2508\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2506\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2507\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2508\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2509\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2510\u001b[39m     step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rinal\\Desktop\\UNIBO\\NLP2\\.venv\\Lib\\site-packages\\transformers\\trainer.py:5224\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5223\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5224\u001b[39m         batch_samples += [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m   5225\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5226\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rinal\\Desktop\\UNIBO\\NLP2\\.venv\\Lib\\site-packages\\accelerate\\data_loader.py:575\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[32m    574\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m         current_batch = \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_state_dict()\n\u001b[32m    577\u001b[39m     next_batch = \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rinal\\Desktop\\UNIBO\\NLP2\\.venv\\Lib\\site-packages\\accelerate\\utils\\operations.py:155\u001b[39m, in \u001b[36msend_to_device\u001b[39m\u001b[34m(tensor, device, non_blocking, skip_keys)\u001b[39m\n\u001b[32m    153\u001b[39m     device = \u001b[33m\"\u001b[39m\u001b[33mxpu:0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rinal\\Desktop\\UNIBO\\NLP2\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:821\u001b[39m, in \u001b[36mBatchEncoding.to\u001b[39m\u001b[34m(self, device, non_blocking)\u001b[39m\n\u001b[32m    816\u001b[39m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[32m    817\u001b[39m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[32m    818\u001b[39m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m    820\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = {\n\u001b[32m--> \u001b[39m\u001b[32m821\u001b[39m         k: \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data.items()\n\u001b[32m    823\u001b[39m     }\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    825\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. This is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    optim=\"adamw_torch\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Define the data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "# Wrap the training process with tqdm for progress tracking\n",
    "for epoch in tqdm(range(training_args.num_train_epochs), desc=\"Epochs\"):\n",
    "    trainer.train()\n",
    "# Save the model\n",
    "trainer.save_model(\"./results\")\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(\"./results\")\n",
    "\n",
    "# # save in an array the training loss and the validation loss\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# get the training loss and validation loss from the trainer\n",
    "for log in trainer.state.log_history:\n",
    "    if \"loss\" in log:\n",
    "        train_loss.append(log[\"loss\"])\n",
    "    if \"eval_loss\" in log:\n",
    "        val_loss.append(log[\"eval_loss\"])\n",
    "\n",
    "# plot the training loss and validation loss\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutation üë®‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9742568866375297\n",
      "Accuracy: 0.9734986965307665\n",
      "Balanced Accuracy: 0.9734986965307666\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation metrics\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Get predictions from the model on the validation dataset\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to label IDs\n",
    "true_predictions = np.argmax(predictions, axis=2).flatten()\n",
    "true_labels = labels.flatten()\n",
    "\n",
    "# Filter out ignored index (-100) in labels\n",
    "valid_indices = true_labels != -100\n",
    "true_predictions = true_predictions[valid_indices]\n",
    "true_labels = true_labels[valid_indices]\n",
    "\n",
    "# Compute F1 score\n",
    "f1_result = metric_f1.compute(predictions=true_predictions, references=true_labels, average=\"weighted\")\n",
    "print(f\"F1 Score: {f1_result['f1']}\")\n",
    "\n",
    "# Compute accuracy\n",
    "acc_result = metric_acc.compute(predictions=true_predictions, references=true_labels)\n",
    "print(f\"Accuracy: {acc_result['accuracy']}\")\n",
    "\n",
    "# Compute balanced accuracy\n",
    "balanced_acc = np.mean([\n",
    "    acc_result['accuracy'] if label != -100 else 0\n",
    "    for label in np.unique(true_labels)\n",
    "])\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  15    0    0 ...    0    0    0]\n",
      " [   0  943    0 ...    0    0    0]\n",
      " [   0    0 1045 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...   37    0    0]\n",
      " [   0    0    0 ...    0  303    0]\n",
      " [   0    0    0 ...    0    0 1073]]\n"
     ]
    }
   ],
   "source": [
    "#compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "#compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, true_predictions, labels=range(len(label_list)))\n",
    "\n",
    "#plot confusion matrix\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with torch.save(model.state_dict(), \"model.pt\")\n",
    "torch.save(model, \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
